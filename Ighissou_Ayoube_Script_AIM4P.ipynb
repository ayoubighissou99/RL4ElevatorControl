{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import Env\n",
    "import gym.spaces as spaces\n",
    "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete\n",
    "\n",
    "# Import Helpers\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torch \n",
    "\n",
    "# Import Stable Baselines Dependencies\n",
    "from stable_baselines3 import PPO, DQN, A2C\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Elevator - 3 Floors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaitingTimeCallback(BaseCallback):\n",
    "    def __init__(self, verbose: int = 0):\n",
    "        super(WaitingTimeCallback, self).__init__(verbose)\n",
    "        self.waiting_times = []\n",
    "    \n",
    "    def _on_step(self) -> bool:\n",
    "        env = self.training_env.envs[0]\n",
    "        waiting_time = self.training_env.waiting_times[-1]\n",
    "        self.waiting_times.append(waiting_time)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Elevator3(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self):\n",
    "        # observation space\n",
    "        # states0: floor_0_up\n",
    "        # states1: floor_1_up\n",
    "        # states2: floor_1_down\n",
    "        # states3: floor_2_up\n",
    "        # states4: floor_2_down\n",
    "        # states5: occupancy\n",
    "        # states6: position\n",
    "        super(Elevator3, self).__init__()\n",
    "\n",
    "        self.done = 0\n",
    "        self.reward = 0\n",
    "        self.states = np.zeros(7)\n",
    "        self.states[0] = 1\n",
    "        self.last_time = 0\n",
    "        self.time = 0\n",
    "        self.max_occupancy = 7\n",
    "        self.waiting_times = []\n",
    "        # The Action step is composed by 3 possible movements\n",
    "        # Action 0 : Stop\n",
    "        # Action 1 : Go Up\n",
    "        # Action 2 : Go Down\n",
    "        self.action_space = spaces.Discrete(3)  # 0 stop, 1 up, 2 down\n",
    "        self.observation_space = spaces.MultiDiscrete([2, 2, 2, 2, 2, 7, 3])\n",
    "        \n",
    "    \n",
    "    def reset(self):\n",
    "        '''\n",
    "            This function allows to reset the env to initial state\n",
    "        '''\n",
    "        self.states = np.zeros(7)\n",
    "        # suppose that there are already 2 people\n",
    "        # waiting on the first floor at the beginning of the session\n",
    "        self.states[0] = 1\n",
    "        self.last_time = 0\n",
    "        self.time = 0\n",
    "        self.floor_0_waiting = 2\n",
    "        self.floor_0_waiting_list = [1, 2]\n",
    "        self.floor_1_waiting = 0\n",
    "        self.floor_1_waiting_list = []\n",
    "        self.floor_2_waiting = 0\n",
    "        self.floor_2_waiting_list = []\n",
    "        self.inside_list = []\n",
    "        self.done = 0\n",
    "        self.reward = 0\n",
    "        self.time_check = []\n",
    "        return self.states\n",
    "\n",
    "    def timecheck(self):\n",
    "        '''\n",
    "            This function Checks the current time in the env and updates accordingly to this the waiting list\n",
    "        '''\n",
    "        if (self.last_time < 5) and (self.time >= 5):\n",
    "            self.floor_1_waiting = 5\n",
    "            self.floor_1_waiting_list.extend(np.random.choice([0, 2], size=self.floor_1_waiting, p=[0.75, 0.25]).tolist())\n",
    "            self.states[1] = 1\n",
    "            self.states[2] = 1\n",
    "\n",
    "        elif (self.last_time < 60) and (self.time >= 60):\n",
    "            self.floor_2_waiting = 5\n",
    "            self.floor_2_waiting_list.extend(np.random.choice([0, 1], size=self.floor_1_waiting, p=[0.75, 0.25]).tolist())\n",
    "            self.states[3] = 1\n",
    "            self.states[4] = 1\n",
    "\n",
    "        if (self.time - self.last_time >= 60) and (self.time < 120):\n",
    "            self.floor_0_waiting_list.extend(np.random.choice([1, 2], size=np.random.choice(2, p=[0.9, 0.1])).tolist())\n",
    "            \n",
    "        self.last_time = self.time\n",
    "\n",
    "    def waiting_list_check(self):\n",
    "\n",
    "        '''\n",
    "            Function to check the waiting list for each floor and updates the corresponding states accordingly \n",
    "        '''\n",
    "\n",
    "        if len(self.floor_0_waiting_list) == 0:\n",
    "            self.states[0] = 0\n",
    "        if 0 not in self.floor_1_waiting_list:\n",
    "            self.states[2] = 0\n",
    "        if 2 not in self.floor_1_waiting_list:\n",
    "            self.states[1] = 0\n",
    "        if 0 not in self.floor_2_waiting_list:\n",
    "            self.states[4] = 0\n",
    "        if 1 not in self.floor_2_waiting_list:\n",
    "            self.states[3] = 0\n",
    "\n",
    "    def done_check(self):\n",
    "\n",
    "        '''\n",
    "            Checking if the episodes are done, by checking all the states. If no people are waiting on any floor and the elevator is empty, we set the flag variable 'done' to 1 indicating that the episode is done\n",
    "            Moreover, is the time exceeds more than 15 minutes, the episodes is considered as well done. This additional constraints is set, as a consequential of the normal behaviour of the people: usually when someone \n",
    "            waits for too long, it will find another way to go to the desired floor (ex. Using the stairs)\n",
    "        '''\n",
    "        if (self.states[0] == 0) and (self.states[2] == 0) and (self.states[1] == 0) and (self.states[4] == 0) and (self.states[3] == 0) and (self.states[6] == 0):\n",
    "            self.done = 1\n",
    "            self.time_check.append(self.time)\n",
    "\n",
    "        elif self.time >= 900:\n",
    "            self.done = 1\n",
    "            print(\"--Waiting More Than 15 Minutes--\")\n",
    "        \n",
    "        if self.done:\n",
    "            self.waiting_times.append(self.time)\n",
    "\n",
    "        return self.done\n",
    "\n",
    "    def rotating_people(self):\n",
    "\n",
    "        '''\n",
    "            This function control the movements of people in the elvator:\n",
    "                If someone reaches the desired floor it will be removed and we add people from the waiting list\n",
    "        '''\n",
    "        self.inside_list = [x for x in self.inside_list if x != self.states[6]]\n",
    "        remaining_places = self.max_occupancy - len(self.inside_list)\n",
    "        if self.states[6] == 0:\n",
    "            if len(self.floor_0_waiting_list) < remaining_places:\n",
    "                self.inside_list.extend(self.floor_0_waiting_list)\n",
    "                self.floor_0_waiting_list = []\n",
    "            else:\n",
    "                self.inside_list.extend(self.floor_0_waiting_list[:remaining_places])\n",
    "                self.floor_0_waiting_list = self.floor_0_waiting_list[remaining_places:]\n",
    "        elif self.states[6] == 1:\n",
    "            if len(self.floor_1_waiting_list) < remaining_places:\n",
    "                self.inside_list.extend(self.floor_1_waiting_list)\n",
    "                self.floor_1_waiting_list = []\n",
    "            else:\n",
    "                self.inside_list.extend(self.floor_1_waiting_list[:remaining_places])\n",
    "                self.floor_1_waiting_list = self.floor_1_waiting_list[remaining_places:]\n",
    "        elif self.states[6] == 2:\n",
    "            if len(self.floor_2_waiting_list) < remaining_places:\n",
    "                self.inside_list.extend(self.floor_2_waiting_list)\n",
    "                self.floor_2_waiting_list = []\n",
    "            else:\n",
    "                self.inside_list.extend(self.floor_2_waiting_list[:remaining_places])\n",
    "                self.floor_2_waiting_list = self.floor_2_waiting_list[remaining_places:]\n",
    "        self.states[5] = len(self.inside_list)\n",
    "\n",
    "    def step(self, action):\n",
    "        '''\n",
    "            It helps to control the elevator movements: \n",
    "                - 0 Stop \n",
    "                - 1 Go Up \n",
    "                - 2 Go Down\n",
    "        '''\n",
    "        info = {}\n",
    "        if self.done:\n",
    "            print(\"END SESSION\")\n",
    "        else:\n",
    "            if action == 0:\n",
    "                self.rotating_people()\n",
    "                self.time += 10\n",
    "            if action == 1:\n",
    "                if self.states[6] == 2:\n",
    "                    print(\"INVALID ACTION!\")\n",
    "                    # If the agent takes an invalid action the rewards will decrease\n",
    "                    self.reward = self.reward - 100\n",
    "                    self.time += 100\n",
    "                else:\n",
    "                    self.time += 2\n",
    "                    self.states[6] = self.states[6] + 1\n",
    "            if action == 2:\n",
    "                if self.states[6] == 0:\n",
    "                    print(\"INVALID ACTION!\")\n",
    "                    self.reward = self.reward - 100\n",
    "                    self.time += 100\n",
    "                else:\n",
    "                    self.time += 2\n",
    "                    self.states[6] = self.states[6] - 1\n",
    "            self.reward = self.reward - (self.states[5] + self.states[2] + self.states[1] + self.states[4] + self.states[3] + self.states[0])\n",
    "            self.timecheck()\n",
    "            self.waiting_list_check()\n",
    "            self.done = self.done_check()\n",
    "\n",
    "\n",
    "        return self.states, self.reward, self.done, info\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train RL Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_elevator_3 = DummyVecEnv([lambda: env_elevator_3])\n",
    "env_elevator_3.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_PATH = os.path.join('TRAIN_PPO','LOGS_PPO')\n",
    "DQN_PATH = os.path.join('TRAIN_DQN','LOGS_DQN')\n",
    "A2C_PATH = os.path.join('TRAIN_A2C','LOGS_A2C')\n",
    "\n",
    "model_elevator_PPO_3 = PPO('MlpPolicy',  # Multi layer perceptron policy\n",
    "                    env_elevator_3, \n",
    "                    verbose = 1,\n",
    "                    tensorboard_log = PPO_PATH,\n",
    "                    learning_rate=0.01,\n",
    "                    gamma = 0.6)\n",
    "\n",
    "model_elevator_DQN_3 = DQN('MlpPolicy',\n",
    "                         env_elevator_3,\n",
    "                         verbose = 1,\n",
    "                         tensorboard_log = DQN_PATH,\n",
    "                         learning_rate=0.01,\n",
    "                         gamma = 0.6)\n",
    "\n",
    "model_elevator_A2C_3 = A2C('MlpPolicy',\n",
    "                         env_elevator_3,\n",
    "                         verbose = 1,\n",
    "                         tensorboard_log = A2C_PATH,\n",
    "                         gamma=0.6,\n",
    "                         learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_elevator_DQN_3.learn(total_timesteps = 500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_elevator_PPO_3.learn(total_timesteps = 500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_elevator_A2C_3.learn(total_timesteps = 500000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Reload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_PATH_save = os.path.join('TRAIN_PPO','SAVED_MODELS_PPO','ppo_saved')\n",
    "DQN_PATH_save = os.path.join('TRAIN_DQN','SAVED_MODELS_PPO','dqn_saved')\n",
    "A2C_PATH_save = os.path.join('TRAIN_A2C','SAVED_MODELS_PPO','a2c_saved')\n",
    "\n",
    "model_elevator_PPO_3.save(PPO_PATH_save)\n",
    "model_elevator_DQN_3.save(DQN_PATH_save)\n",
    "model_elevator_A2C_3.save(A2C_PATH_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model_elevator_A2C_3, \n",
    "                env_elevator_3, \n",
    "                n_eval_episodes = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model_elevator_PPO_3, \n",
    "                env_elevator_3, \n",
    "                n_eval_episodes = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model_elevator_DQN_3, \n",
    "                env_elevator_3, \n",
    "                n_eval_episodes = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env_elevator_3.reset()\n",
    "while True:\n",
    "    action, _states = model_elevator_PPO_3.predict(obs)\n",
    "    obs, rewards, done, info = env_elevator_3.step(action)\n",
    "    if done: \n",
    "        print('info', info)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env_elevator_3.reset()\n",
    "while True:\n",
    "    action, _states = model_elevator_DQN_3.predict(obs)\n",
    "    obs, rewards, done, info = env_elevator_3.step(action)\n",
    "    if done: \n",
    "        print('info', info)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env_elevator_3.reset()\n",
    "while True:\n",
    "    action, _states = model_elevator_A2C_3.predict(obs)\n",
    "    obs, rewards, done, info = env_elevator_3.step(action)\n",
    "    if done: \n",
    "        print('info', info)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log_path_ppo = os.path.join(PPO_PATH, 'PPO_3')\n",
    "training_log_path_dqn = os.path.join(DQN_PATH, 'DQN_3')\n",
    "training_log_path_a2c = os.path.join(A2C_PATH, 'A2C_1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir={training_log_path_a2c} --port={6015}\n",
    "# ok from there DQN works very well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir={training_log_path_ppo} --port={6011}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir={training_log_path_dqn} --port={6012}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callback Training Phase - PPO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save = os.path.join('training', 'saved_models')\n",
    "path_log = os.path.join('training','logs')\n",
    "\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_elevator = Elevator3()\n",
    "env_elevator = DummyVecEnv([lambda : env_elevator])\n",
    "\n",
    "stop_CB = StopTrainingOnRewardThreshold(reward_threshold=  200, verbose = 1)\n",
    "eval_CB = EvalCallback( env_elevator,\n",
    "                       callback_on_new_best=stop_CB,\n",
    "                       eval_freq= 10000,\n",
    "                       best_model_save_path=path_to_save,\n",
    "                       verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO('MlpPolicy', env_elevator, tensorboard_log= path_log, verbose = 1)\n",
    "model.learn(total_timesteps=20000, callback = eval_CB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join('training','saved_models','best_model')\n",
    "model = PPO.load(model_path, env = env_elevator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env_elevator, n_eval_episodes = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo =os.path.join(path_log,'PPO_2') \n",
    "ppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir={ppo} --port={6013}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
